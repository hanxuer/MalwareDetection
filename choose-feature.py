from sklearn.ensemble import RandomForestClassifier as RF
from sklearn import model_selection
from sklearn.metrics import confusion_matrix
import pandas as pd
import numpy as np
from sklearn.metrics import roc_curve
from sklearn.metrics import auc
import matplotlib.pyplot as plt
import math
subtrainLabel = pd.read_csv('subtrainLabels.csv')
avg = lambda items: float(sum(items)) / len(items)


for i in range(1,4):

    subtrainfeature_3 = pd.read_csv("TF_{0}feature.csv".format(50*i))
    #subtrainfeature_3 = pd.read_csv("TFIDF_{0}feature.csv".format(50,i))
    subtrain_3 = pd.merge(subtrainLabel,subtrainfeature_3,on='Id')
    labels_3 = subtrain_3.Class
    subtrain_3.drop(["Class","Id"], axis=1, inplace=True)
    subtrain_3 = subtrain_3.values
    X_train_3, X_test_3, y_train_3, y_test_3 = model_selection.train_test_split(subtrain_3,labels_3,test_size=0.5)

    srf_3 = RF(n_estimators=10, n_jobs=-1)
    srf_3.fit(X_train_3,y_train_3)
    print(srf_3.score(X_test_3,y_test_3))

    y_pred = srf_3.predict(X_test_3)
    #print(confusion_matrix(y_test_3, y_pred))
    CM = confusion_matrix(y_test_3, y_pred)
    FP = CM.sum(axis=0) - np.diag(CM)  
    FN = CM.sum(axis=1) - np.diag(CM)
    TP = np.diag(CM)
    TN = CM.sum() - (FP + FN + TP)
    #print(FP,FN,TP,TN)

    FP = FP.astype(float)
    FN = FN.astype(float)
    TP = TP.astype(float)
    TN = TN.astype(float)

    TPR = TP/(TP+FN)
# Specificity or true negative rate
    TNR = TN/(TN+FP) 
# Precision or positive predictive value
    PPV = TP/(TP+FP)
# Negative predictive value
    NPV = TN/(TN+FN)
# Fall out or false positive rate
    FPR = FP/(FP+TN)
# False negative rate
    FNR = FN/(TP+FN)
# False discovery rate
    FDR = FP/(TP+FP)
# Overall accuracy
    ACC = (TP+TN)/(TP+FP+FN+TN)
    Gmean = math.sqrt(avg(TNR)*avg(TPR))
    print(avg(TPR),avg(FPR),avg(ACC),Gmean,end="\t")
    print()

