import re
from collections import *
import os
import pandas as pd

from sklearn import feature_extraction
import sklearn
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.feature_extraction.text import CountVectorizer

#从asm文件提取opcode
def getOpcodeSequence(filename):
    print(filename)
    opcode_seq = []
    p = re.compile(r'\s([a-fA-F0-9]{2}\s)+\s*([a-z]+)')
    with open(filename,encoding='gb18030',errors='ignore') as f:
        for line in f:
            if line.startswith(".text"):
                m = re.findall(p,line)
                if m:
                    opc = m[0][1]
                    if opc != "align":
                        opcode_seq.append(opc)
    with open("opcode.txt",'w') as f2:
        f2.writelines(opcode_seq)
        f2.write("\t")
    #print(opcode_seq)
    return opcode_seq

transformer = TfidfTransformer()
vectorizer = CountVectorizer(analyzer='char')
ops_corus = []

#n-gram
def getOpcodeNgram(ops, n):
    opngramlist = [tuple(ops[i:i+n]) for i in range(len(ops)-n)]
    opngram = Counter(opngramlist)
    #TF
    '''
    values_sum = sum(opngram.values())
    for k in opngram:
        opngram[k] = opngram[k]/values_sum
    '''
    return opngram

basepath = "D:\MyDownloads\\train\\subtrain\\"
mapgram = defaultdict(Counter)
subtrain = pd.read_csv('subtrainLabels.csv')
for i in range(1,6):
    count = 1
    for sid in subtrain.Id:
        print ("counting the {0}-gram of the {1} file...".format(i,str(count)))
        count += 1
        filename = basepath + sid + ".asm"
        ops = getOpcodeSequence(filename)
        opgram = getOpcodeNgram(ops,i)
        ops_corus.append(' '.join(str(opgram).strip()))
        mapgram[sid] = opgram
    
    ops_count = vectorizer.fit_transform(ops_corus)
#统计每一个词语的tfdif值
    tfidf = transformer.fit_transform(ops_count)
#获取词袋模型中所有的词语
    word = vectorizer.get_feature_names()
#将tf-idf矩阵抽取出来,元素a[i][j]表示此词在i类文本中的权重
    weight = tfidf.toarray()
    cc = Counter([])
    for d in mapgram.values():
        cc += d
    selectedfeatures = {}
    tc = 0
#select top 50 by DF
    for k,v in cc.most_common(50):
        selectedfeatures[k] = v
        print (k,v)
        tc += 1
    dataframelist = []
    j = 0
    for fid,opgram in mapgram.items():
        standard = {}
        standard["Id"] = fid
        for feature in selectedfeatures:
            if feature in opgram:
                standard[feature] = opgram[feature]
            else:
                standard[feature] = 0
        dataframelist.append(standard)
        j += 1
    df = pd.DataFrame(dataframelist)
    df.to_csv("TFIDF_top50_{0}feature.csv".format(i),index=False)

